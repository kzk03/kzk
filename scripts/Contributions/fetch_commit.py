import os
import time

import pandas as pd
import requests
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_dotenv("config/.env")

# GitHub API èªè¨¼æƒ…å ±ã‚’.envã‹ã‚‰å–å¾—
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")

if not GITHUB_TOKEN:
    raise ValueError("GITHUB_TOKEN ãŒ .env ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

HEADERS = {"Authorization": f"token {GITHUB_TOKEN}"}

# å–å¾—ã™ã‚‹é–‹ç™ºè€…ãƒªã‚¹ãƒˆã®CSVãƒ•ã‚¡ã‚¤ãƒ«
developer_list_file = "/Users/kazuki-h/newresearch/results/unique_developer_list.csv"  # å®Ÿéš›ã®ãƒ‘ã‚¹ã«å¤‰æ›´
developers_df = pd.read_csv(developer_list_file)

# å–å¾—ã™ã‚‹æ—¥ä»˜ç¯„å›²ã‚’æŒ‡å®š
SINCE_DATE = "2005-01-01T00:00:00Z"  # â† ã“ã“ã‚’å¤‰æ›´ã™ã‚Œã°é–‹å§‹æ—¥ã‚’æŒ‡å®šå¯èƒ½
UNTIL_DATE = "2024-12-31T23:59:59Z"  # â† ã“ã“ã§çµ‚äº†æ—¥ã‚’æŒ‡å®š

# ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
output_dir = "/Users/kazuki-h/newresearch/results/commit_history"
os.makedirs(output_dir, exist_ok=True)

# APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ç¢ºèªã™ã‚‹é–¢æ•°
def check_rate_limit(response):
    if response.status_code == 403 and "X-RateLimit-Reset" in response.headers:
        reset_time = int(response.headers["X-RateLimit-Reset"])
        current_time = int(time.time())
        wait_time = reset_time - current_time
        if wait_time > 0:
            print(f"âš  APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¾ã™...")
            time.sleep(wait_time + 1)  # å®‰å…¨ã®ãŸã‚1ç§’ä½™åˆ†ã«å¾…æ©Ÿ
        return True
    return False

# å„é–‹ç™ºè€…ã®ã‚³ãƒŸãƒƒãƒˆå±¥æ­´ã‚’å–å¾—ã—ã€å€‹åˆ¥ã®CSVã«ä¿å­˜
for developer in developers_df['developer'].dropna():
    print(f"Fetching commits for {developer} from {SINCE_DATE} to {UNTIL_DATE}...")
    commit_data = []  # å€‹åˆ¥ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    page = 1

    while True:
        url = f"https://api.github.com/search/commits?q=author:{developer}+committer-date:{SINCE_DATE}..{UNTIL_DATE}&sort=committer-date&per_page=100&page={page}"
        
        response = requests.get(url, headers=HEADERS)

        if check_rate_limit(response):
            continue  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¾Œã«å†è©¦è¡Œ

        if response.status_code != 200:
            print(f"Error fetching {developer}: {response.status_code}")
            break

        commits = response.json().get('items', [])
        if not commits:
            break

        for commit in commits:
            commit_data.append([
                developer,
                commit['repository']['full_name'],
                commit['sha'],
                commit['commit']['message'],
                commit['commit']['committer']['date']
            ])

        page += 1
        time.sleep(1)  # APIåˆ¶é™ã‚’é¿ã‘ã‚‹ãŸã‚ã«é…å»¶ã‚’æŒ¿å…¥

    # DataFrame ã«å¤‰æ›
    if commit_data:
        commit_df = pd.DataFrame(commit_data, columns=['developer', 'repo', 'commit_sha', 'commit_message', 'commit_date'])

        # å„é–‹ç™ºè€…ã”ã¨ã«CSVä¿å­˜
        developer_filename = os.path.join(output_dir, f"{developer}.csv")
        commit_df.to_csv(developer_filename, index=False, encoding="utf-8")

        print(f"âœ… {developer} ã®ã‚³ãƒŸãƒƒãƒˆå±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {developer_filename}")
    else:
        print(f"âš  {developer} ã®ã‚³ãƒŸãƒƒãƒˆå±¥æ­´ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

print("ğŸ‰ ã™ã¹ã¦ã®ã‚³ãƒŸãƒƒãƒˆå±¥æ­´ã®å–å¾—ã¨ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
