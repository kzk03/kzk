import os
import time

import pandas as pd
import requests
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_dotenv("config/.env")

# GitHub API èªè¨¼æƒ…å ±ã‚’.envã‹ã‚‰å–å¾—
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")

if not GITHUB_TOKEN:
    raise ValueError("GITHUB_TOKEN ãŒ .env ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

HEADERS = {"Authorization": f"token {GITHUB_TOKEN}"}

# å–å¾—ã™ã‚‹é–‹ç™ºè€…ãƒªã‚¹ãƒˆã®CSVãƒ•ã‚¡ã‚¤ãƒ«
developer_list_file = "/Users/kazuki-h/newresearch/results/B.csv"
developers_df = pd.read_csv(developer_list_file)

# å–å¾—ã™ã‚‹æ—¥ä»˜ç¯„å›²ã‚’æŒ‡å®š
SINCE_DATE = "2005-01-01T00:00:00Z"
UNTIL_DATE = "2024-12-31T23:59:59Z"

# ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
output_dir = "/Users/kazuki-h/newresearch/results/commit_history"
os.makedirs(output_dir, exist_ok=True)

# APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ç¢ºèªã™ã‚‹é–¢æ•°
def check_rate_limit(response):
    if response.status_code == 403 and "X-RateLimit-Reset" in response.headers:
        reset_time = int(response.headers["X-RateLimit-Reset"])
        current_time = int(time.time())
        wait_time = reset_time - current_time
        if wait_time > 0:
            print(f"âš  APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¾ã™...")
            time.sleep(wait_time + 1)
        return True
    return False

# å„é–‹ç™ºè€…ã®ã‚³ãƒŸãƒƒãƒˆå±¥æ­´ã‚’å–å¾—ã—ã€å€‹åˆ¥ã®CSVã«ä¿å­˜
for developer in developers_df['developer'].dropna():
    print(f"Fetching commits for {developer} from {SINCE_DATE} to {UNTIL_DATE}...")
    commit_data = []  # å€‹åˆ¥ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    page = 1

    while True:
        url = f"https://api.github.com/search/commits?q=author:{developer}+committer-date:{SINCE_DATE}..{UNTIL_DATE}&sort=committer-date&per_page=100&page={page}"
        
        response = requests.get(url, headers=HEADERS)

        if check_rate_limit(response):
            continue  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¾Œã«å†è©¦è¡Œ

        if response.status_code != 200:
            print(f"Error fetching {developer}: {response.status_code}")
            break

        commits = response.json().get('items', [])
        if not commits:
            break

        for commit in commits:
            sha = commit['sha']
            repo_name = commit['repository']['full_name']
            commit_message = commit['commit']['message']
            commit_date = commit['commit']['committer']['date']

            # å„ã‚³ãƒŸãƒƒãƒˆã®å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—
            commit_details_url = f"https://api.github.com/repos/{repo_name}/commits/{sha}"
            commit_response = requests.get(commit_details_url, headers=HEADERS)

            if check_rate_limit(commit_response):
                continue  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¾Œã«å†è©¦è¡Œ

            if commit_response.status_code == 200:
                commit_details = commit_response.json()
                changed_files = [file['filename'] for file in commit_details.get('files', [])]
            else:
                print(f"âš  ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {commit_details_url}")
                changed_files = []

            commit_data.append([
                developer,
                repo_name,
                sha,
                commit_message,
                commit_date,
                ", ".join(changed_files)  # å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§ä¿å­˜
            ])

        page += 1
        time.sleep(1)

    # DataFrame ã«å¤‰æ›
    if commit_data:
        commit_df = pd.DataFrame(commit_data, columns=['developer', 'repo', 'commit_sha', 'commit_message', 'commit_date', 'changed_files'])

        # å„é–‹ç™ºè€…ã”ã¨ã«CSVä¿å­˜
        developer_filename = os.path.join(output_dir, f"{developer}.csv")
        commit_df.to_csv(developer_filename, index=False, encoding="utf-8")

        print(f"âœ… {developer} ã®ã‚³ãƒŸãƒƒãƒˆå±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {developer_filename}")
    else:
        print(f"âš  {developer} ã®ã‚³ãƒŸãƒƒãƒˆå±¥æ­´ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

print("ğŸ‰ ã™ã¹ã¦ã®ã‚³ãƒŸãƒƒãƒˆå±¥æ­´ã®å–å¾—ã¨ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸï¼")